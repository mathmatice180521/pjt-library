import json
import math
import re
import base64
import time
import logging  # [ì¶”ê°€] ì—ëŸ¬ ë¡œê·¸ ì¶œë ¥ì„ ìœ„í•´ í•„ìš”
from typing import Iterable, List, Optional

import requests
import urllib3
# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

from django.conf import settings
from django.core.files.base import ContentFile
from django.db.models import Q 

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# SSAFY GMS í”„ë¡ì‹œ
GEMINI_BASE_URL = "https://gms.ssafy.io/gmsapi/generativelanguage.googleapis.com"


# =========================================================
# ê³µí†µ ìœ í‹¸
# =========================================================
def _strip_code_fence(s: str) -> str:
    if not s: return s
    s = s.strip()
    s = re.sub(r"^```(?:json)?\s*", "", s, flags=re.IGNORECASE)
    s = re.sub(r"\s*```$", "", s)
    return s.strip()

def _strip_wrapping_quotes(s: str) -> str:
    s = (s or "").strip()
    if len(s) >= 2 and ((s[0] == s[-1] == '"') or (s[0] == s[-1] == "'")):
        return s[1:-1].strip()
    return s

def _extract_json(text: str):
    if not text: return None
    t = _strip_code_fence(text)
    try: return json.loads(t)
    except Exception: pass
    m = re.search(r"(\[[\s\S]*?\]|\{[\s\S]*?\})", t)
    if not m: return None
    candidate = m.group(1).strip()
    candidate = re.sub(r",\s*([\]}])", r"\1", candidate)
    try: return json.loads(candidate)
    except Exception: return None

def _normalize_space(s: str) -> str:
    s = (s or "").replace("\n", " ").strip()
    s = re.sub(r"\s+", " ", s)
    return s.strip()


# =========================================================
# ë¶ˆìš©ì–´ ë° í—¬í¼ í•¨ìˆ˜
# =========================================================
STOPWORDS = {
    "ì¶”ì²œ", "í•´ì¤˜", "í•´ì£¼ì„¸ìš”", "ì¢‹ì€", "ìš”ì¦˜", "ìµœê·¼", "ë§ì´", "ìœ„ì£¼", "ëŠë‚Œ",
    "ì±…", "ë„ì„œ", "ì†Œì„¤", "ì½ì„", "ì½ê³ ", "ì½ì–´", "ì‹¶ì–´", "ì›í•´", "ì›í•©ë‹ˆë‹¤",
    "ì¥ë¥´", "ë¶„ìœ„ê¸°", "ì¬ë°ŒëŠ”", "ì¬ë¯¸ìˆëŠ”", "ì¬ë¯¸", "ë² ìŠ¤íŠ¸ì…€ëŸ¬",
    "ëŒ€í•œ", "ê´€ë ¨", "ê´€í•œ", "ìœ„í•œ", "ê³ ë¯¼", "ê±±ì •", "ìƒê°", "ë§ì•„", "ì¢€", "ì•½ê°„",
    "ë‚´ìš©", "ì¤„ê±°ë¦¬", "ì£¼ì œ", "ì•Œë ¤ì¤˜", "ì°¾ì•„ì¤˜", "ì†Œê°œ", "ëª©ë¡", "ë¹„ìŠ·í•œ",
    "ë¬´ìŠ¨", "ì–´ë–¤", "ê²ƒ", "ë“±", "ë‚˜ì˜¤ëŠ”", "ìˆëŠ”"
}

def extract_keywords_fallback(text: str, *, limit: int = 8) -> list[str]:
    tokens = re.findall(r"[ê°€-í£A-Za-z0-9]{2,}", (text or "").lower())
    out: list[str] = []
    for t in tokens:
        if t in STOPWORDS: continue
        if t not in out: out.append(t)
        if len(out) >= limit: break
    return out

def build_keyword_filter_q(keywords: list[str]) -> Q:
    q = Q()
    for kw in keywords:
        q |= Q(title__icontains=kw)
        q |= Q(description__icontains=kw)
        q |= Q(category__name__icontains=kw)
        q |= Q(publisher__icontains=kw)
    return q


# =========================================================
# 1) Gemini generateContent (ì•ˆì „ì¥ì¹˜ ì¶”ê°€ë¨)
# =========================================================
def _gemini_generate_text(prompt: str, *, force_json: bool = True) -> str:
    api_key = getattr(settings, "GEMINI_API_KEY", "")
    model = getattr(settings, "GEMINI_MODEL", "gemini-2.5-flash")
    if not api_key: raise ValueError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    url = f"{GEMINI_BASE_URL}/v1beta/models/{model}:generateContent?key={api_key}"
    generation_config = {"temperature": 0.3, "topP": 0.8, "topK": 40, "maxOutputTokens": 800}
    if force_json: generation_config["responseMimeType"] = "application/json"

    payload = {"contents": [{"parts": [{"text": prompt}]}], "generationConfig": generation_config}
    headers = {"Content-Type": "application/json", "x-goog-api-key": api_key}

    try:
        # [ìˆ˜ì •] timeout ì„¤ì • ë° ì˜ˆì™¸ ì²˜ë¦¬
        resp = requests.post(url, json=payload, headers=headers, timeout=(5, 20), verify=False)
        resp.raise_for_status() # 400, 500 ì—ëŸ¬ ì‹œ ì˜ˆì™¸ ë°œìƒ
        return resp.json()["candidates"][0]["content"]["parts"][0]["text"]
    except Exception as e:
        # ì—ëŸ¬ê°€ ë‚˜ë©´ ë¡œê·¸ë¥¼ ì°ê³  ë¹ˆ ë¬¸ìì—´ ë°˜í™˜ (í˜¸ì¶œí•˜ëŠ” ìª½ì—ì„œ ì²˜ë¦¬)
        logger.error(f"Gemini API Error: {e}")
        return "" # ë¹ˆ ë¬¸ìì—´ ë°˜í™˜í•˜ì—¬ fallback ìœ ë„

def build_user_preference_text(v: dict) -> str:
    lines = [f"- ììœ ìš”ì²­: {v.get('prompt', '')}"]
    if v.get("mood"): lines.append(f"- ë¶„ìœ„ê¸°: {v['mood']}")
    themes = v.get("themes") or []
    if themes: lines.append(f"- ì›í•˜ëŠ” ì£¼ì œ/ìš”ì†Œ: {', '.join(themes)}")
    length = v.get("length")
    if length: lines.append(f"- ë¶„ëŸ‰ ì„ í˜¸: {length}")
    return "\n".join(lines).strip()

def extract_intent_json(user_prompt: str) -> dict:
    p = (user_prompt or "").strip()
    prompt = f"""
ë„ˆëŠ” í•œêµ­ì–´ ë¬¸ì¥ ì´í•´ ì „ë¬¸ê°€ë‹¤.
ì‚¬ìš©ì ì…ë ¥ì„ 'ë„ì„œ ì¶”ì²œ'ì— ì“°ê¸° ì¢‹ê²Œ êµ¬ì¡°í™”(JSON)í•´ë¼.
[ì‚¬ìš©ì ì…ë ¥] {p}
ì¶œë ¥ì€ JSONë§Œ. ìŠ¤í‚¤ë§ˆ:
{{
  "intent": "í•œ ì¤„ ì˜ë„(20~40ì)",
  "core_topics": ["í•µì‹¬ ì£¼ì œ 1~5ê°œ(ëª…ì‚¬ ì¤‘ì‹¬)"],
  "mood": "ê°ì •/ë¶„ìœ„ê¸°(ì—†ìœ¼ë©´ null)",
  "request_type": "ìœ í˜•(ìœ„ë¡œ/ì¡°ì–¸/ì •ë³´ ë“±, ì—†ìœ¼ë©´ null)",
  "avoid": ["í”¼í•˜ê³  ì‹¶ì€ ê²ƒ"],
  "notes": "ì¶”ê°€ ì œì•½"
}}
ê·œì¹™: 'ì±…', 'ì¶”ì²œ', 'ë‚´ìš©' ë“± ë©”íƒ€ ë‹¨ì–´ ì œì™¸. ì£¼ì œëŠ” í¥ë¯¸ ì†Œì¬ ì¤‘ì‹¬.
""".strip()

    raw = _gemini_generate_text(prompt, force_json=True)
    if not raw: return {} # ì—ëŸ¬ë‚˜ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬

    data = _extract_json(raw)
    if not isinstance(data, dict): data = {}

    intent = data.get("intent")
    core = data.get("core_topics") or []
    
    filtered_core = []
    for t in core:
        t_clean = str(t).strip()
        if t_clean in STOPWORDS: continue
        if t_clean.endswith("ê´€ë ¨"): t_clean = t_clean[:-2]
        if t_clean and t_clean not in STOPWORDS: filtered_core.append(t_clean)
    data["core_topics"] = filtered_core

    if not data["core_topics"] and p:
        cleaned_p = p.replace("ì¶”ì²œ", "").replace("í•´ì¤˜", "").strip()
        if cleaned_p: data["core_topics"] = [cleaned_p[:10]]

    if not isinstance(data.get("avoid"), list): data["avoid"] = []
    return data


# =========================================================
# 2) Gemini embedContent
# =========================================================
def _sanitize_text(s: str, max_chars: int) -> str:
    s = re.sub(r"[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]", " ", (s or ""))
    return re.sub(r"\s+", " ", s).strip()[:max_chars]

def gemini_embed_text(text: str, *, task_type="RETRIEVAL_QUERY", title=None) -> List[float]:
    api_key = getattr(settings, "GEMINI_API_KEY", "")
    model = getattr(settings, "GEMINI_EMBED_MODEL", "text-embedding-004")
    if not api_key: raise ValueError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    url = f"{GEMINI_BASE_URL}/v1beta/models/{model}:embedContent?key={api_key}"
    payload = {"content": {"parts": [{"text": _sanitize_text(text, 2500)}]}}
    headers = {"Content-Type": "application/json", "x-goog-api-key": api_key}

    try:
        resp = requests.post(url, json=payload, headers=headers, timeout=(5, 10), verify=False)
        if resp.status_code != 200: 
            logger.error(f"Embedding Error: {resp.text}")
            return [] # ì‹¤íŒ¨ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸
        return resp.json()["embedding"]["values"]
    except Exception as e:
        logger.error(f"Embedding Exception: {e}")
        return []

def gemini_batch_embed_texts(texts: List[str], *, _depth: int = 0) -> List[List[float]]:
    if not texts: return []
    api_key = getattr(settings, "GEMINI_API_KEY", "")
    model = getattr(settings, "GEMINI_EMBED_MODEL", "text-embedding-004")
    if not api_key: raise ValueError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    max_text_chars = int(getattr(settings, "AI_MAX_EMBED_CHARS", 2500))
    safe_texts = [_sanitize_text(t, max_text_chars) for t in texts]

    url = f"{GEMINI_BASE_URL}/v1beta/models/{model}:batchEmbedContents?key={api_key}"
    headers = {"Content-Type": "application/json", "x-goog-api-key": api_key}
    payload = {"requests": [{"model": f"models/{model}", "content": {"parts": [{"text": t}]}} for t in safe_texts]}

    try:
        resp = requests.post(url, json=payload, headers=headers, timeout=(10, 60), verify=False)
        if resp.status_code != 200:
            logger.error(f"Batch Embed Error: {resp.text}")
            if _depth >= 3: return [[] for _ in texts] # ì¬ì‹œë„ íšŸìˆ˜ ì¤„ì„
            # ì¬ì‹œë„ ë¡œì§ ìœ ì§€
            mid = len(texts) // 2
            left = gemini_batch_embed_texts(texts[:mid], _depth=_depth + 1)
            right = gemini_batch_embed_texts(texts[mid:], _depth=_depth + 1)
            return left + right

        data = resp.json()
        embeddings = data.get("embeddings") or []
        return [e.get("values", []) for e in embeddings]
    except Exception as e:
        logger.error(f"Batch Embed Exception: {e}")
        return [[] for _ in texts]


# =========================================================
# 3) Vector math
# =========================================================
def vector_norm(v: Iterable[float]) -> float:
    return math.sqrt(sum((x * x) for x in v))

def cosine_similarity(a: List[float], b: List[float], *, norm_a=None, norm_b=None) -> float:
    if not a or not b or len(a) != len(b): return -1.0
    na = norm_a or vector_norm(a)
    nb = norm_b or vector_norm(b)
    if na == 0 or nb == 0: return -1.0
    return sum(x*y for x,y in zip(a,b)) / (na * nb)

def build_book_document_text(book) -> str:
    cat = book.category.name if getattr(book, "category", None) else ""
    desc = (book.description or "").replace("\n", " ").strip()
    return f"ì œëª©: {book.title}\nì €ì: {getattr(book,'author','')}\në¶„ë¥˜: {cat}\nì†Œê°œ: {desc}"

def ensure_book_embedding(book, *, force: bool = False):
    from ai.models import BookEmbedding
    obj, _ = BookEmbedding.objects.get_or_create(book=book)
    if obj.embedding and obj.embedding_norm and not force:
        return obj.embedding, float(obj.embedding_norm)
    
    emb = gemini_embed_text(build_book_document_text(book))
    if not emb: return [], 0.0 # ì„ë² ë”© ì‹¤íŒ¨ì‹œ ë¹ˆ ê°’

    n = vector_norm(emb)
    obj.embedding = emb
    obj.embedding_norm = n
    obj.embedding_model = getattr(settings, "GEMINI_EMBED_MODEL", "text-embedding-004")
    obj.save()
    return emb, n


# =========================================================
# [ìˆ˜ì •] 5) Reason Generation (ì¶”ì²œ ì‚¬ìœ  ìƒì„± ê°œì„  - ì•ˆì „ì¥ì¹˜)
# =========================================================

def _trim_to_sentence_end(s: str, max_len: int = 250) -> str:
    s = _normalize_space(s)
    if len(s) <= max_len:
        return s
    
    truncated = s[:max_len]
    match = list(re.finditer(r'[.!?](?:\s|$)', truncated))
    
    if match:
        last_match = match[-1]
        return truncated[:last_match.end()].strip()
    else:
        return truncated.strip() + "..."

# Fallback ë¬¸êµ¬
def heuristic_reason(*, book, user_keywords: List[str], mood: Optional[str], themes: List[str]) -> str:
    cat = book.category.name if getattr(book, "category", None) else "ì´ ë¶„ì•¼"
    return f"'{book.title}'ì€ {cat} ë¶„ì•¼ì˜ ìˆ˜ì‘ìœ¼ë¡œ, ìš”ì²­í•˜ì‹  ì£¼ì œì— ëŒ€í•´ ê¹Šì´ ìˆëŠ” í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ì±…ì„ í†µí•´ ìƒˆë¡œìš´ ê´€ì ì„ ì–»ìœ¼ì‹¤ ìˆ˜ ìˆì„ ê±°ì˜ˆìš”."

def generate_reason_for_book(*, user_pref_text, user_keywords, mood, themes, book, match_keywords) -> str:
    cat_name = book.category.name if getattr(book, "category", None) else ""
    desc = (book.description or "").replace("\n", " ").strip()
    desc = desc[:400]

    prompt = f"""
ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  í†µì°°ë ¥ ìˆëŠ” 'AI ë„ì„œ íë ˆì´í„° ì›…ì„±ì´'ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ê³ ë¯¼ì´ë‚˜ ê´€ì‹¬ì‚¬ì— ë§ì¶° ì´ ì±…ì„ ì¶”ì²œí•˜ëŠ” ì´ìœ ë¥¼ ì•„ë˜ **í˜•ì‹**ì— ë§ì¶° ì‘ì„±í•´ì£¼ì„¸ìš”.

[ì‚¬ìš©ì ìƒí™©/ìš”ì²­]
"{user_pref_text}"

[ì±… ì •ë³´]
- ì œëª©: {book.title}
- ë¶„ë¥˜: {cat_name}
- ë‚´ìš©: {desc}

â˜…í•„ìˆ˜ ì‘ì„± í˜•ì‹â˜…:
"{user_pref_text}"ì— ëŒ€í•´ ê´€ì‹¬ì´ ìˆìœ¼ì‹œêµ°ìš”. ì´ ì±…ì„ ì¶”ì²œí•´ ë“œë¦½ë‹ˆë‹¤.
ì´ ì±…ì˜ ì¤„ê±°ë¦¬ëŠ” (ì¤„ê±°ë¦¬ ìš”ì•½) ì…ë‹ˆë‹¤.
(ì¶”ì²œ ì´ìœ  1), (ì¶”ì²œ ì´ìœ  2) ë•Œë¬¸ì— ì‚¬ìš©ìë‹˜ì—ê²Œ í° ë„ì›€ì´ ë  ê²ƒì…ë‹ˆë‹¤.

â˜…ì‘ì„± ê·œì¹™â˜…:
1. DBì— ì±… ë‚´ìš©ì´ ë¶€ì¡±í•˜ë©´ ë‹¹ì‹ ì˜ ì§€ì‹(Internal Knowledge)ì„ í™œìš©í•´ ì¤„ê±°ë¦¬ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì±„ìš°ì„¸ìš”.
2. ì¶”ì²œ ì´ìœ ëŠ” ì‚¬ìš©ìì˜ ìƒí™©ê³¼ ì—°ê²°í•˜ì—¬ êµ¬ì²´ì ì¸ í•´ê²°ì±…ì´ë‚˜ ìœ„ë¡œê°€ ë˜ë„ë¡ ì“°ì„¸ìš”.
3. ë¬¸ì¥ì€ ë°˜ë“œì‹œ 'ì…ë‹ˆë‹¤/í•©ë‹ˆë‹¤' ì²´ë¡œ ì •ì¤‘í•˜ê²Œ ëë§ºìœ¼ì„¸ìš”.
4. ì¤‘ê°„ì— ë¬¸ì¥ì´ ì˜ë¦¬ì§€ ì•Šë„ë¡ ì™„ê²°ëœ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. (ê³µë°± í¬í•¨ 200~250ì ë‚´ì™¸)
""".strip()

    try:
        # [ìˆ˜ì •] ì—¬ê¸°ì„œ ì—ëŸ¬ ë°œìƒì‹œ heuristic_reasonìœ¼ë¡œ ë°”ë¡œ ë„˜ì–´ê°
        raw = _gemini_generate_text(prompt, force_json=False)
        if not raw: # AI ì‘ë‹µì´ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš°
            raise ValueError("AI generation failed")

        txt = _strip_wrapping_quotes(_strip_code_fence(raw)).strip()
        final_reason = _trim_to_sentence_end(txt, 280)
        
        if len(final_reason) < 30: 
            return heuristic_reason(book=book, user_keywords=user_keywords, mood=mood, themes=themes)
            
        return final_reason
    except Exception as e:
        # ë¡œê·¸ ì¶œë ¥ í›„ ì•ˆì „í•˜ê²Œ ê¸°ë³¸ ë©˜íŠ¸ ë°˜í™˜
        logger.warning(f"Reason Gen Failed for {book.title}: {e}")
        return heuristic_reason(book=book, user_keywords=user_keywords, mood=mood, themes=themes)


# =========================================================
# 6) Imagen 4.0 4ì»· ë§Œí™” ìƒì„± (ì•ˆì „ì¥ì¹˜ ì¶”ê°€)
# =========================================================
def generate_comic_image_file(book_title: str, book_summary: str) -> ContentFile:
    api_key = getattr(settings, "GEMINI_API_KEY", "")
    if not api_key: raise ValueError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    url = f"{GEMINI_BASE_URL}/v1beta/models/imagen-4.0-generate-001:predict"

    # [ë‹¨ê³„ 1] ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
    scenario_prompt = f"""
    You are a visual storyteller. I need a description for a 4-panel comic strip about the book "{book_title}".
    Current Book Summary: "{book_summary[:500]}"
    Task:
    1. If the summary is short, use your OWN KNOWLEDGE about the book to fill in the plot.
    2. Create a visual description for 4 panels.
    3. Output ONLY the English description.
    """
    
    enriched_description = _gemini_generate_text(scenario_prompt, force_json=False)
    if not enriched_description:
        enriched_description = f"Comic about {book_title}. {book_summary}"

    # [ë‹¨ê³„ 2] Imagenì—ê²Œ ì´ë¯¸ì§€ ìƒì„± ìš”ì²­
    prompt_text = f"""
    Create a high-quality 4-panel comic strip based on this description:
    {enriched_description[:800]}

    Style & Constraints:
    - Webtoon / Manhwa style, colorful, expressive characters.
    - **STRICTLY SILENT COMIC (NO TEXT, NO BUBBLES)**: Do NOT include any speech bubbles, dialogue boxes, or written text inside the panels.
    - Visual Storytelling: Use body language and background to convey the meaning without words.
    - Clear division between 4 panels.
    """

    payload = {
        "instances": [{"prompt": prompt_text}],
        "parameters": {"sampleCount": 1}
    }
    headers = {"Content-Type": "application/json", "x-goog-api-key": api_key}

    print(f"ğŸ”¥ [DEBUG] Imagen ìš”ì²­ ì‹œì‘ (Title: {book_title})")

    try:
        resp = requests.post(url, json=payload, headers=headers, timeout=50, verify=False)
        if resp.status_code != 200:
            raise ValueError(f"Imagen API ì‹¤íŒ¨ ({resp.status_code}): {resp.text}")

        data = resp.json()
        b64_data = data["predictions"][0]["bytesBase64Encoded"]
        img_content = base64.b64decode(b64_data)
        file_name = f"comic_{int(time.time())}.png"
        return ContentFile(img_content, name=file_name)
    except Exception as e:
        logger.error(f"Imagen Gen Failed: {e}")
        raise ValueError(f"ì´ë¯¸ì§€ ìƒì„± ì¤‘ í†µì‹  ì—ëŸ¬: {e}")
